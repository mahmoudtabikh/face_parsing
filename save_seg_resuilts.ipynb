{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import cv2\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from PIL import Image\n",
    "from ibug.face_detection import RetinaFacePredictor\n",
    "from ibug.face_parsing import FaceParser as RTNetPredictor\n",
    "from ibug.face_parsing.utils import label_colormap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid stages [True, True, True]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.8 # default = 0.8\n",
    "weights = None # r\"C:\\mahmoud_dev\\machine learning\\segmentation\\face_parsing\\ibug\\face_parsing\\rtnet\\weights\\rtnet101-fcn-14.torch\" # default = None\n",
    "num_classes = 14 # default = 11\n",
    "max_num_faces = 50 # default = 50\n",
    "\n",
    "parser_encoder = 'rtnet50'\n",
    "parser_decoder = 'fcn'\n",
    "rotate_image = False\n",
    "today = date.today()\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "face_detector = RetinaFacePredictor(threshold=threshold, device=device, model=(RetinaFacePredictor.get_model('mobilenet0.25')))\n",
    "face_parser = RTNetPredictor(device=device, ckpt=weights, encoder=parser_encoder, decoder=parser_decoder, num_classes=num_classes)\n",
    "\n",
    "def get_image_pred(img, face_detector, face_parser):\n",
    "    if rotate_image:\n",
    "        img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "    faces = face_detector(img, rgb=False)\n",
    "    masks = face_parser.predict_img(img, faces, rgb=False)\n",
    "    \n",
    "    return faces, masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_list = ['background', 'skin', 'left_eyebrow', 'nose', 'upper_lip', 'inner_mouth', 'lower_lip',\n",
    "                   'right_eyebrow', 'left_eye', 'hair', 'left_ear', 'right_ear', 'right_eye', 'glasses']\n",
    "\n",
    "categories = [{\"name\":category, \"id\":i} for i, category in enumerate(categories_list)]\n",
    "\n",
    "# Initialize COCO format dictionary\n",
    "coco_dict = {\n",
    "    'info': {\"contributor\":\"mahmoud tabikh\",\"date_created\":date.today().strftime('%d-%m-%Y'),\"description\":\"\",\"url\":\"\",\"version\":\"\",\"year\":\"\"},\n",
    "    'licenses': [{\"name\":\"\",\"id\":0,\"url\":\"\"}],\n",
    "    'categories': categories,\n",
    "    'images': [],\n",
    "    'type': 'instances',\n",
    "    'annotations': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and filenames\n",
    "image_dir = r'D:\\_Xchng\\Mahmoud\\segmenation\\dataset\\data\\raw_images'\n",
    "json_filepath = r'D:\\_Xchng\\Mahmoud\\segmenation\\dataset\\data\\instances_default.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def working_save_segmentation_coco(image_dir):\n",
    "    # Loop through images in directory\n",
    "    for image_id, filename in enumerate(os.listdir(image_dir)):\n",
    "        if filename.endswith(tuple([\".png\", \".jpg\"])):\n",
    "\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            image_dict = { \n",
    "                'id': image_id+1,\n",
    "                'width': image.shape[1],\n",
    "                'height': image.shape[0],\n",
    "                'file_name': filename}\n",
    "            coco_dict['images'].append(image_dict)\n",
    "\n",
    "            faces, masks = get_image_pred(image, face_detector, face_parser)\n",
    "            mask_arr, face = masks[0], faces[0] # assumes 1 face per image, loop for more faces.\n",
    "\n",
    "            annotations_list = get_annotations_list(mask_arr, face, image_id+1, coco_dict[\"annotations\"])\n",
    "            for dict_ in annotations_list:\n",
    "                coco_dict['annotations'].append(dict_)\n",
    "\n",
    "    save_json(coco_dict)\n",
    "\n",
    "\n",
    "def save_segmentation_yolo(image_dir):\n",
    "    # Save segmentation results in YOLO format\n",
    "    with open('segmentation_result.txt', 'w') as f:\n",
    "        for i, obj in enumerate(objects):\n",
    "            bbox = obj['bbox']\n",
    "            segmentation_mask = segmentation_results[i]\n",
    "            obj_center_x = (bbox[0] + bbox[2]) / 2.0\n",
    "            obj_center_y = (bbox[1] + bbox[3]) / 2.0\n",
    "            obj_width = bbox[2] - bbox[0]\n",
    "            obj_height = bbox[3] - bbox[1]\n",
    "            pixel_coords = np.argwhere(segmentation_mask == 1)\n",
    "            pixel_coords_str = ','.join([f\"{x[1]},{x[0]}\" for x in pixel_coords])\n",
    "            line = f\"0 {obj_center_x} {obj_center_y} {obj_width} {obj_height} {pixel_coords_str}\\n\"\n",
    "            f.write(line)\n",
    "\n",
    "\n",
    "def get_annotations_list(mask_arr, face, image_id, dict_):\n",
    "    # Create annotation dictionary for each unique mask value\n",
    "    annotation_list = [] # i am making a list of lists instead of list of dicts\n",
    "    for value in np.unique(mask_arr):\n",
    "        if value != 0:\n",
    "            annotation_id = len(dict_) + 1\n",
    "            mask_bool = mask_arr == value\n",
    "            annotation_dict = {\n",
    "                'id': int(annotation_id),\n",
    "                'image_id': int(image_id),\n",
    "                'category_id': value,\n",
    "                'segmentation': [],\n",
    "                'area': np.sum(mask_bool),\n",
    "                'bbox': face[:4].astype(int),\n",
    "                'iscrowd': 0,\n",
    "                'ignore': 0}\n",
    "            # Create segmentation and bbox arrays\n",
    "            ys, xs = np.where(mask_bool)\n",
    "            segmentation = np.asarray(list(zip(xs, ys))).flatten().tolist()\n",
    "            annotation_dict['segmentation'].append(segmentation)\n",
    "            annotation_list.append(annotation_dict)\n",
    "    # Add annotation to COCO dictionary\n",
    "    return annotation_list\n",
    "\n",
    "def save_json(coco_dict):\n",
    "    class NpEncoder(json.JSONEncoder):\n",
    "        def default(self, obj):\n",
    "            if isinstance(obj, np.integer):\n",
    "                return int(obj)\n",
    "            if isinstance(obj, np.floating):\n",
    "                return float(obj)\n",
    "            if isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            return super(NpEncoder, self).default(obj)\n",
    "    Path(json_filepath).write_text(json.dumps(coco_dict, cls=NpEncoder, indent=3))\n",
    "    print(f\"json file written to {json_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\contours.cpp:197: error: (-210:Unsupported format or combination of formats) [Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL otherwise supports CV_32SC1 images only in function 'cvStartFindContours_Impl'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m save_segmentation_coco(image_dir)\n",
      "Cell \u001b[1;32mIn[47], line 19\u001b[0m, in \u001b[0;36msave_segmentation_coco\u001b[1;34m(image_dir)\u001b[0m\n\u001b[0;32m     16\u001b[0m faces, masks \u001b[39m=\u001b[39m get_image_pred(image, face_detector, face_parser)\n\u001b[0;32m     17\u001b[0m mask_arr, face \u001b[39m=\u001b[39m masks[\u001b[39m0\u001b[39m], faces[\u001b[39m0\u001b[39m] \u001b[39m# assumes 1 face per image, loop for more faces.\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m annotations_list \u001b[39m=\u001b[39m get_annotations_list(mask_arr, face, image_id\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m, coco_dict[\u001b[39m\"\u001b[39;49m\u001b[39mannotations\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m dict_ \u001b[39min\u001b[39;00m annotations_list:\n\u001b[0;32m     21\u001b[0m     coco_dict[\u001b[39m'\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(dict_)\n",
      "Cell \u001b[1;32mIn[47], line 33\u001b[0m, in \u001b[0;36mget_annotations_list\u001b[1;34m(mask_arr, face, image_id, dict_)\u001b[0m\n\u001b[0;32m     30\u001b[0m annotation_id \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dict_) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     31\u001b[0m mask_bool \u001b[39m=\u001b[39m mask_arr \u001b[39m==\u001b[39m value\n\u001b[1;32m---> 33\u001b[0m contours, _ \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mfindContours(mask_arr, cv2\u001b[39m.\u001b[39;49mRETR_EXTERNAL, cv2\u001b[39m.\u001b[39;49mCHAIN_APPROX_SIMPLE)\n\u001b[0;32m     35\u001b[0m \u001b[39m# Calculate the area of the largest contour\u001b[39;00m\n\u001b[0;32m     36\u001b[0m largest_contour_area \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\contours.cpp:197: error: (-210:Unsupported format or combination of formats) [Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL otherwise supports CV_32SC1 images only in function 'cvStartFindContours_Impl'\n"
     ]
    }
   ],
   "source": [
    "save_segmentation_coco(image_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_parse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
