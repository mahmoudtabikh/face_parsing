{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import cv2\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "from ibug.face_detection import RetinaFacePredictor\n",
    "from ibug.face_parsing import FaceParser as RTNetPredictor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid stages [True, True, True]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.8 # default = 0.8\n",
    "weights = None # r\"C:\\mahmoud_dev\\machine learning\\segmentation\\face_parsing\\ibug\\face_parsing\\rtnet\\weights\\rtnet101-fcn-14.torch\" # default = None\n",
    "num_classes = 14 # default = 11\n",
    "max_num_faces = 50 # default = 50\n",
    "\n",
    "parser_encoder = 'rtnet50'\n",
    "parser_decoder = 'fcn'\n",
    "rotate_image = False\n",
    "today = date.today()\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "face_detector = RetinaFacePredictor(threshold=threshold, device=device, model=(RetinaFacePredictor.get_model('mobilenet0.25')))\n",
    "face_parser = RTNetPredictor(device=device, ckpt=weights, encoder=parser_encoder, decoder=parser_decoder, num_classes=num_classes)\n",
    "\n",
    "def get_image_pred(img, face_detector, face_parser):\n",
    "    if rotate_image:\n",
    "        img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    faces = face_detector(img, rgb=False)\n",
    "    masks = face_parser.predict_img(img, faces, rgb=False)\n",
    "    return faces, masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'background', 'id': 0}, {'name': 'skin', 'id': 1}, {'name': 'left_eyebrow', 'id': 2}, {'name': 'right_eyebrow', 'id': 3}, {'name': 'left_eye', 'id': 4}, {'name': 'right_eye', 'id': 5}, {'name': 'nose', 'id': 6}, {'name': 'upper_lip', 'id': 7}, {'name': 'inner_mouth', 'id': 8}, {'name': 'lower_lip', 'id': 9}, {'name': 'hair', 'id': 10}, {'name': 'left_ear', 'id': 11}, {'name': 'right_ear', 'id': 12}, {'name': 'glasses', 'id': 13}]\n"
     ]
    }
   ],
   "source": [
    "categories_list = ['background', 'skin', 'left_eyebrow', 'right_eyebrow', 'left_eye', 'right_eye',\n",
    "                 'nose', 'upper_lip', 'inner_mouth', 'lower_lip', 'hair']\n",
    "\n",
    "if num_classes==14:\n",
    "    categories_list.extend(['left_ear', 'right_ear',  'glasses'])\n",
    "\n",
    "categories = [{\"name\":category, \"id\":i} for i, category in enumerate(categories_list)]\n",
    "\n",
    "print(categories)\n",
    "# Initialize COCO format dictionary\n",
    "coco_dict = {\n",
    "    'info': {\"contributor\":\"mahmoud_tabikh\",\"date_created\":date.today().strftime('%d-%m-%Y'),\"description\":\"\", \"version\":\"\"},\n",
    "    'licenses': [],\n",
    "    'categories': categories,\n",
    "    'images': [],\n",
    "    'annotations': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and filenames\n",
    "image_dir = r'D:\\_Xchng\\Mahmoud\\segmenation\\dataset\\data\\raw_images'\n",
    "json_filepath = r'D:\\_Xchng\\Mahmoud\\segmenation\\dataset\\data\\instances_default.json'\n",
    "txt_filepath = r'D:\\_Xchng\\Mahmoud\\segmenation\\dataset\\data\\yolo_annotations\\obj_train_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different segmentation methods\n",
    "\n",
    "def get_segmenation_xy(mask, class_id):\n",
    "    # Create segmentation and bbox arrays\n",
    "    mask_bool = mask == class_id\n",
    "    area = np.sum(mask_bool)\n",
    "\n",
    "    ys, xs = np.where(mask_bool)\n",
    "    segmentation = np.asarray(list(zip(xs, ys))).flatten().tolist()\n",
    "    return area, segmentation\n",
    "\n",
    "def get_segmentation_countours(mask, class_id):\n",
    "    # Create segmentation and bbox arrays\n",
    "    mask_bool = mask == class_id\n",
    "    area = np.sum(mask_bool)\n",
    "\n",
    "    retrieval_method = cv2.RETR_EXTERNAL # options: cv2.RETR_EXTERNAL, cv2.RETR_TREE\n",
    "    contour_approximation = cv2.CHAIN_APPROX_SIMPLE # options: cv2.CHAIN_APPROX_SIMPLE, cv2.CHAIN_APPROX_NONE\n",
    "    contours, hierarchy = cv2.findContours(mask_bool.astype(np.uint8), retrieval_method, contour_approximation)\n",
    "    segmentations = []\n",
    "    for contour in contours:\n",
    "        if len(contour) < 3:\n",
    "            continue\n",
    "        segmentation = []\n",
    "        for point in contour:\n",
    "            segmentation.extend(point.flatten().tolist())\n",
    "        segmentations.append(segmentation)\n",
    "    return area, segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_segmentation_coco(image_dir):\n",
    "    # Loop through images in directory\n",
    "    for image_id, filename in enumerate(os.listdir(image_dir)):\n",
    "        if filename.endswith(tuple([\".png\", \".jpg\"])):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            image_id+=1\n",
    "            image = cv2.imread(image_path)\n",
    "            image_dict = { \n",
    "                'id': image_id,\n",
    "                'width': image.shape[1],\n",
    "                'height': image.shape[0],\n",
    "                'file_name': filename}\n",
    "            coco_dict['images'].append(image_dict)\n",
    "            faces, masks = get_image_pred(image, face_detector, face_parser)\n",
    "            mask, face = masks[0], faces[0] # assumes 1 face per image, loop for more faces.\n",
    "            # plt.imshow(mask)\n",
    "            # plt.show()\n",
    "            annotations_list = get_annotations_list(mask, face, image_id, coco_dict[\"annotations\"])\n",
    "            for dict_ in annotations_list:\n",
    "                coco_dict['annotations'].append(dict_)\n",
    "    save_json(coco_dict)\n",
    "\n",
    "\n",
    "def get_annotations_list(mask, face, image_id, coco_annotation_dict):\n",
    "    # Create annotation dictionary for each unique mask value\n",
    "    annotation_list = [] # i am making a list of lists instead of list of dicts\n",
    "    for class_id in np.unique(mask):\n",
    "        if class_id != 0:\n",
    "            annotation_id = len(coco_annotation_dict) + 1\n",
    "            annotation_dict = {\n",
    "                'id': annotation_id,\n",
    "                'image_id': image_id,\n",
    "                'category_id': class_id,\n",
    "                'segmentation': [],\n",
    "                'bbox': face[:4].astype(int),\n",
    "                'iscrowd': 0}\n",
    "            area, segmentations = get_segmentation_countours(mask, class_id)\n",
    "            annotation_dict['segmentation'].extend(segmentations)\n",
    "            annotation_dict['area'] = area\n",
    "            annotation_list.append(annotation_dict)\n",
    "    # Add annotation to COCO dictionary\n",
    "    return annotation_list\n",
    "\n",
    "def save_json(coco_dict):\n",
    "    class NpEncoder(json.JSONEncoder):\n",
    "        def default(self, obj):\n",
    "            if isinstance(obj, np.integer):\n",
    "                return int(obj)\n",
    "            if isinstance(obj, np.floating):\n",
    "                return float(obj)\n",
    "            if isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            return super(NpEncoder, self).default(obj)\n",
    "    Path(json_filepath).write_text(json.dumps(coco_dict, cls=NpEncoder, indent=3))\n",
    "    print(f\"json file written to {json_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json file written to D:\\_Xchng\\Mahmoud\\segmenation\\dataset\\data\\instances_default.json\n"
     ]
    }
   ],
   "source": [
    "save_segmentation_coco(image_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_parse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
